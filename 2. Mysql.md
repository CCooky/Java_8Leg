# 一、关系型数据库基础知识

## **1、数据库**

- **存储和管理数据的仓库，数据是有组织的进行存储。**
- 数据库英文名是 DataBase，简称DB。

顾名思义，**关系型数据库（RDBMS，Relational Database Management System）**就是一种**建立在关系模型的基础上**的数据库。关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。

## **2、数据库管理系统**

- **管理数据库的大型软件**
- 英文：DataBase Management System，简称 DBMS

在电脑上安装了数据库管理系统后，就可以通过数据库管理系统创建数据库来存储数据，也可以通过该系统对数据库中的数据进行数据的增删改查相关的操作。**我们平时说的MySQL数据库其实是MySQL数据库管理系统。**

<img src="images/image-20230211144320915.png" alt="image-20230211144320915" style="zoom:80%;" />

​		常见的数据库管理系统：

<img src="images/image-20220124213936400.png" alt="image-20220124213936400" style="zoom:80%;" />

接下来对上面列举的数据库管理系统进行简单的介绍：

- Oracle：收费的大型数据库，Oracle 公司的产品
- **MySQL： 开源免费的中小型数据库。后来 Sun公司收购了 MySQL，而 Sun 公司又被 Oracle 收购**
- SQL Server：MicroSoft 公司收费的中型的数据库。C#、.net 等语言常使用
- PostgreSQL：开源免费中小型的数据库
- DB2：IBM 公司的大型收费数据库产品
- SQLite：嵌入式的微型数据库。如：作为 Android 内置数据库
- MariaDB：开源免费中小型的数据库

## **==3、SQL语言==**

==这么多的管理系统，怎么学的完呢，对不对？，所以我们统一了一门编程语言（SQL）来操作所有的DBMS。整理一下，**用户、DBMS、DB的关系**，如下：==

<img src="images/image-20220124214718322.png" alt="image-20220124214718322" style="zoom:80%;" />

用户通过SQL语言跟数据库管理系统（DMBS）打交道 ；然后DBMS识别用户的命令，来对数据库（DB）进行增删改查的操作。

- **英文：Structured Query Language，简称 SQL，结构化查询语言**
- 操作==关系型数据库==的编程语言
- ==大部分数据库管理系统的sql语句都是一样的，但是也存在部分的需求，它的语法规则不一样，这种我们称为——数据库管理系统的方言。==

**SQL分类**

- **DDL(Data Definition Language) ：** 数据定义语言，**用来操作数据库， 表属性 等**
- **DML(Data Manipulation Language)** ：数据操作语言，对**表中数据进行增删改**

- **DQL(Data Query Language)** 数据查询语言，**对表中数据进行查询。**

<img src="images/image-20220125142429771.png" alt="image-20220125142429771" style="zoom:80%;" />

- **DCL(Data Control Language)** 数据控制语言。**对数据库、表进行权限控制**。比如我让某一个数据库表只能让某一个用户进行操作等。



**DQL包括以下几种查询，很广泛！！！**

- 基础查询；
- 条件查询
- 排序查询；
- 分组查询（聚合函数）；
- 分页查询；
- 多表查询；
  - 内连接 
  - 外连接
  - 子查询 

```sql
# 不区分大小写，逗号分割，分号结束
SHOW DATABASES;
USE 数据库名称;
SHOW TABLES;
CREATE TABLE stutable ( 
  字段名1 数据类型1, 
  字段名2 数据类型2, 
  …
  字段名n 数据类型n 
);
-- 注意：最后一行末尾，不能加逗号
DROP TABLE IF EXISTS stutable;
alter table stu add address varchar(50);

INSERT INTO 表名(列名1,列名2,…) VALUES(值1,值2,…),(值1,值2,…),(值1,值2,…)…; 
update stu set sex="女" where name = "张三";
delete from stu where name = '张三'; 
```

```sql
SELECT 
		(distinct) 字段列表 
FROM
		表名列表 
WHERE
		条件列表 （条件查询）
				and  or  between..and..  in(..)  like %王%  is null  is not null
ORDER BY 
		排序字段 （排序查询）
				order by math desc, english asc ;
LIMIT
		分页限定 （分页查询）	
		LIMIT 起始索引, 每页条目数。查询第三页的数据，每页显示3条 limit 3*(3-1),3;
    
### group by 【where 不能对聚合函数进行判断，having 可以。】
SELECT 分组字段,聚合函数(任意字段) FROM 表名 
[WHERE 分组前条件限定] 
GROUP BY 分组字段 [HAVING 分组后条件限制]; 

【select sex,avg(math),COUNT(*) from stu where math >= 70 GROUP BY sex HAVING count(*)>2;】

#聚合函数 将一列数据作为一个整体，进行纵向计算。null值不参与所有聚合函数运算
可以就看出是一个查询的字段，只是这个字段不在表里面
【聚合函数】 count(一个字段)、max(..)、min(..)、sum(..)、avg(..)
select count(*) from stu; 
select max(math) from stu;
```

```sql
### 多表查询
【隐式内连接】
SELECT 字段列表 FROM 表1,表2… WHERE 条件;
		select t1.NAME,t1.age,t2.dep_name 
		from emp as t1, dept as t2 where t1.dep_id= t2.did;

【显示内连接】
需求：查询已经分配部门的员工个人信息和部门信息
SELECT 字段列表 FROM 表1 JOIN 表2 ON 条件;
		select * from emp inner join dept on emp.dep_id = dept.did;
		
【左外连接（这里的左右指的是表1、表2的相对位置）】
需求：查询所有员工的个人信息和部门信息
SELECT 字段列表 FROM 表1 LEFT JOIN 表2 ON 条件;
	 	select * from emp left join dept on emp.dep_id = dept.did;

【右外连接】
需求：查询部门信息以及部门内员工信息
SELECT 字段列表 FROM 表1 RIGHT JOIN 表2 ON 条件;

【子查询/嵌套查询】
需求：查询工资高于猪八戒的员工信息。'子查询结果是单行单列作为条件值，使用>,<,=这种'
select * from emp where salary > (select salary from emp where name = '猪八戒');

需求：查询 财务部和市场部所有的员工信息。'多行单列使用in等关键字'
select *from emp where dep_id in (select did from dept where dname in ("财务部","市场部"));

需求：查询入职日期是'2011-11-11'之后的员工信息和z部门信息。'多行多列，作为虚拟表。'
select * from 
(select * from emp where join_date > '2011-11-11' ) as t1, dept as t2
where t1.dep_id = t2.did;

select * from emp,dept where 
emp.id in (SELECT id from emp where join_date > "2011-11-11") 
and emp.id = dept.did;
```

### 实战案例

预警记录里面存放了桥梁id和监测类型id，返回前端的数据里面需要桥梁名称和监测类型名称。（is_deal=0——表示未处理的预警记录；is_deal=1——表示已经处理过的预警记录）

```sql
select t1.*,t2.bridge_name,t3.monitor_type_name
from bridge_alert_record as t1 
JOIN bridge_manage as t2 on t1.bridge_id=t2.bridge_id and t1.is_deal=1
JOIN bridge_monitor_type as t3 on t1.monitor_type_id = t3.monitor_type_id;
```

谷粒学院

```sql
SELECT *
from edu_course as ec 
left join edu_course_description as ecd on ec.id=ecd.id
LEFT JOIN edu_teacher as et on ec.teacher_id=et.id
LEFT JOIN edu_subject as es1 on ec.subject_parent_id=es1.id
LEFT JOIN edu_subject as es2 on ec.subject_id=es2.id
whree ec.id=?
```





## 4、ER图

就是对数据库表中的设计，思路。==搞清楚表之间的关系，以及单张表的结构==

数据库设计的步骤

* 需求分析（数据是什么? 数据具有哪些属性? 数据与属性的特点是什么）

* 逻辑分析（通过ER图对数据库进行逻辑建模，不需要考虑我们所选用的数据库管理系统）

  如下图就是==ER(Entity/Relation)图==：（现在已经不需要画这个了，Mysql那个模型转换功能就可以看见）

<img src="images/image-20220126210624242.png" alt="image-20220126210624242" style="zoom: 50%;" />

这个就是：emp表有一个外键指向了dept表，外键是dep_id字段到dept的id。

<img src="images/image-20230211145644908.png" alt="image-20230211145644908" style="zoom:80%;" />

**表之间的关系：**

- 一对一（一个表拆分成两个表，用于提高查询性能），
- 一对多，（部门与员工之间的关系；一个部门对应多个员工，一个员工属于一个部门）
- 多对多。（商品与订单的关系。一个商品对应会有多个订单，一个订单里面有多个商品。）

## 5、数据库范式了解吗?

数据库范式有 3 种：

- 第一范式: 即数据库表的每一列都是不可分割的原子数据项。**也就是这个字段只能是一个值**，不能再分为多个其他的字段了
- 第二范式:要求**实体的属性完全依赖于主关键字**。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性。
- 第三范式:**任何非主属性不依赖于其它非主属性**。

**1NF(第一范式)**

属性（对应于表中的字段）不能再被分割，也就是这个字段只能是一个值，不能再分为多个其他的字段了。**1NF 是所有关系型数据库的最基本要求** ，也就是说关系型数据库中创建的表一定满足第一范式。

**2NF(第二范式)**

2NF 在 1NF 的基础之上，消除了非主属性对于码（列）的部分函数依赖。如下图所示，展示了第一范式到第二范式的过渡。**第二范式在第一范式的基础上增加了一个列，这个列称为主键，非主属性都依赖于主键。**

<img src="images/bd1d31be3779342427fc9e462bf7f05c.png" alt="第二范式" style="zoom: 80%;" />

**3NF(第三范式)**

3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。符合 3NF 要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖，所以该表的设计，不符合 3NF 的要求。

## **==6、主键和外键有什么区别?为什么不推荐使用外键与级联==**

**主键(主码)** ：主键用于唯一标识一个元组，不能有重复，不允许为空。一个表只能有一个主键。

**外键(外码)** ：外键用来和其他表建立联系用，外键是另一表的主键，**外键是可以有重复的，可以是空值。一个表可以有多个外键。**



==不得使用外键与级联，一切外键概念必须在应用层解决。==

说明: 以学生和成绩的关系为例，学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，即**为级联更新**。外键与级联更新适用于单机低并发，不适合分布式、高并发集群。

 **级联更新**是强阻塞，存在数据库更新风暴的风 险; 

**外键：**

- **增加了开发复杂性。**

  每次做 DELETE 或者 UPDATE 都必须考虑外键约束，会导致开发的时候很痛苦, 测试数据极为不方便; b. 外键的主从关系是定的，假如那天需求有变化，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦。

- **降低数据库效率**

  数据库需要增加维护外键的工作，比如当我们做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，保证数据的的一致性和正确性，这样会不得不消耗资源；）

- **对分库分表不友好** ：因为分库分表下外键是无法生效的。



# 二、MySQL存储、索引

## 1、MySQL数据类型

MySQL 支持多种类型，可以分为三类：

数值

```sql
tinyint	:小整数型，占一个字节 
int			:大整数类型，占四个字节 
						eg ： age int 
double	:浮点类型 
				使用格式： 字段名 double(总长度,小数点后保留的位数) 
						eg ： score double(5,2)
```

 日期

```sql
date			:日期值。只包含年月日 
							eg ：birthday date 
datetime	:混合日期和时间值。包含"年-月-日-时-分-秒"
```

字符串

```sql
char		:定长字符串。 
				优点：存储性能高 
				缺点：浪费空间 如果存储的数据字符个数不足10个，也会占10个的空间 
					eg ： name char(10) 
varchar	:变长字符串。 
				优点：节约空间 
				缺点：存储性能低 如果存储的数据字符个数不足255个，那就数据字符个数是几就占几个的空间 
					eg ： name varchar(255) 
```



## ==1.一个 SQL 语句在 MySQL 中的执行流程（阿里）==

下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到客户端的一条 SQL 语句在 MySQL 内部是如何执行的。

<img src="images/13526879-3037b144ed09eb88.png" alt="img" style="zoom:80%;" />

从上图可以看出， MySQL 主要由下面几部分构成：

- **连接器：** **身份权限验证**(登录 MySQL 的时候)。与客户端进行 **TCP 三次握手**建立连接
- **查询缓存：** 执行**查询**语句的时候，会先查询缓存，如果命中则直接返回结果。
  - （MySQL 8.0 版本后移除，这个功能不太实用，因为对于更新频繁的表，根本没有用）
  - MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条查询命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为查询 SQL 语句，value 为 SQL 语句的结果。
- **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
- **优化器：** 按照 MySQL 认为最优的方案去执行。**如将 SQL 语句的执行方案确定下来**，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。
- **执行器：** 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。
- **插件式存储引擎** ： 主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的**索引数据结构，就是由存储引擎层实现的**，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 



##  ==2.**MySQL 一行记录是怎么存储的？**==

> 知道了这个之后，除了能应解锁前面这道面试题，你还会解锁这些面试题：
>
> - MySQL 的 NULL 值会占用空间吗？
> - MySQL 怎么知道 varchar(n) 实际占用数据的大小？
> - varchar(n) 中 n 最大取值为多少？
> - 行溢出后，MySQL 是怎么处理的？
>
> 这些问题看似毫不相干，其实都是在围绕==「 MySQL 一行记录的存储结构」==这一个知识点，所以攻破了这个知识点后，这些问题就引刃而解了。

### **1、先来看看 MySQL 数据库的文件存放在哪个目录？**

> 【windows】
>
> ```sql
> create database db1;
> ```
>
> 这样就在数据库按照目录下的data文件下，新建一个db1的文件夹；即在MySQL中一个数据库对应到磁盘上的一个文件夹。
>
> 然后一个数据库下可以创建多张表，我们到MySQL中自带的mysql数据库的文件夹目录下：
>
> <img src="images/image-20220125140047241.png" alt="image-20220125140047241" style="zoom:80%;" />
>
> <img src="images/image-20230211181017312.png" alt="image-20230211181017312" style="zoom: 67%;" />
>
> 上图中右边的 **db.frm 是表文件**， **db.MYD 是数据文件**，通过这两个文件就可以查询到数据展示成二维表的效果。
>
> 1. **MySQL中可以创建多个数据库，每个数据库对应到磁盘上的一个文件夹**
> 2. **在每个数据库中可以创建多个表，每张都对应到磁盘上一个 frm 文件**
> 3. **每张表可以存储多条数据，数据会被存储到磁盘中 MYD 文件中**

【Linux】

​		同Windows模式一样

新建数据库DB1：在 /var/lib/mysql/ 目录里面创建一个以 DB1为名的目录；然后保存表结构和表数据的文件都会存放在这个目录里。

新建一张表：比如，我这里有一个名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。我们进入 /var/lib/mysql/my_test 目录，看看里面有什么文件？

<img src="images/image-20230211162945748.png" alt="image-20230211162945748" style="zoom:80%;" />

可以看到，共有三个文件，这三个文件分别代表着：

- **db.opt**，用来存储当前数据库的默认字符集和字符校验规则。
- **t_order.frm** ，t_order 的**表结构**会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。
- **t_order.ibd**，t_order 的**表数据**会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。

好了，现在我们知道了一张数据库表的数据是保存在**「 表名字.ibd 」**的文件里的，这个文件也称为**独占表空间文件**。



### **2、表空间文件的结构是怎么样的？**

表空间由**段（segment）、区（extent）、页（page）、行（row）**组成，InnoDB存储引擎的逻辑存储结构大致如下图：

<img src="images/表空间结构.drawio.png" alt="img" style="zoom:80%;" />

**1、行（row）**

数据库表中的==记录都是按行（row）进行存放的==，每行记录根据不同的行格式，有不同的存储结构。

后面我们详细介绍 **InnoDB 存储引擎的行格式**，也是本文重点介绍的内容。

**2、页（page）16kb**

记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。

因此，==InnoDB 的数据是按「页」为单位来读写的==，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。

==页是 InnoDB 存储引擎磁盘管理的最小单元（16KB）==，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中

页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。数据表中的行记录是用「数据页」来管理的，数据页的结构这里我就不讲细说了，之前文章有说过，感兴趣的可以去看这篇文章：[换一个角度看 B+ 树(opens new window)](https://xiaolincoding.com/mysql/index/page.html)

==总之知道表中的记录存储在「数据页」里面就行。==

**3、区（extent）**

我们知道 InnoDB 存储引擎是用 B+ 树来组织数据的。

B+ 树中叶子节点都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。

解决这个问题也很简单，就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I/O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。

那具体怎么解决呢？

**在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了**。

**4、段（segment）**

表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。

- ==索引段：存放 B + 树的非叶子节点的区的集合；==
- 数据段：存放 B + 树的叶子节点的区的集合；
- 回滚段：存放的是回滚数据的区的集合，之前讲[事务隔离 (opens new window)](https://xiaolincoding.com/mysql/transaction/mvcc.html)的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。

好了，终于说完==表空间的结构==了。接下来，就具体讲一下 ==InnoDB 的行格式==了。之所以要绕一大圈才讲行记录的格式，主要是想让大家知道行记录是存储在哪个文件，以及行记录在这个表空间文件中的哪个区域，有一个从上往下切入的视角，这样理解起来不会觉得很抽象。



### **3、InnoDB 行格式有哪些？**

==行格式（row_format），就是一条记录的存储结构。==

InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。

- Redundant 是==很古老==的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。
- 由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式，==Compact 是一种紧凑的行格式==，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式==默认设置成 Compact==。
- Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。从 ==MySQL5.7 版本之后，默认使用 Dynamic 行格式==。

所以，弄懂了 Compact 行格式，之后你们在去了解其他行格式，很快也能看懂。

**3.1、COMPACT 行格式长什么样？**

先跟 Compact 行格式混个脸熟，它长这样：

<img src="images/COMPACT.drawio.png" alt="img" style="zoom:80%;" />

可以看到，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。

**记录的额外信息**。记录的额外信息包含 3 个部分：变长字段长度列表、NULL 值列表、记录头信息。

- ==**1. 变长字段长度列表（2个字节）**==

varchar(n) 和 char(n) 的区别是什么，相信大家都非常清楚，char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。	

所以，在存储数据的时候，也要把数据占用的大小存起来，存到==「变长字段长度列表」==里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。其他 TEXT、BLOB 等变长字段也是这么实现的。

==变长字段字节数列表不是必须的。==当数据表没有变长字段的时候，比如全部都是 int 类型的字段，这时候表里的行格式就不会有「变长字段长度列表」了，因为没必要，不如去掉以节省空间

**举一个例子说明：（后面都是这个例子）**

我们先创建这样一张表，字符集是 ascii（所以每一个字符占用的 1 字节），行格式是 Compact，t_user 表中 ==name 和 phone 字段都是变长字段varchar==：

现在 t_user 表里有这三条记录：

<img src="images/t_test.png" alt="img" style="zoom:80%;" />

接下来，我们看看看看这三条记录的行格式中的 「变长字段长度列表」是怎样存储的。

先来看第一条记录：

- name 列的值为 a，真实数据占用的字节数是 1 字节，十六进制 0x01；
- phone 列的值为 123，真实数据占用的字节数是 3 字节，十六进制 0x03；
- age 列和 id 列不是变长字段，所以这里不用管。

这些变长字段的真实数据占用的字节数会按照列的顺序**逆序存放**（等下会说为什么要这么设计），所以「变长字段长度列表」里的内容是「 03 01」，而不是 「01 03」。

<img src="images/变长字段长度列表1.png" alt="img" style="zoom: 33%;" />

同样的道理，我们也可以得出**第二条记录**的行格式中，「变长字段长度列表」里的内容是「 04 02」，如下图：

<img src="images/变长字段长度列表2.png" alt="img" style="zoom:33%;" />

**第三条记录**中 phone 列的值是 NULL，**NULL 是不会存放在行格式中记录的真实数据部分里的**，所以「变长字段长度列表」里不需要保存值为 NULL 的变长字段的长度。

<img src="images/变长字段长度列表3.png" alt="img" style="zoom:33%;" />

==变长字段字节数列表不是必须的。==当数据表没有变长字段的时候，比如全部都是 int 类型的字段，这时候表里的行格式就不会有「变长字段长度列表」了，因为没必要，不如去掉以节省空间。



- ==**2. NULL 值列表（1个字节）**==

表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。

**如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit）**，二进制位按照列的顺序逆序排列。

- 二进制位的值为`1`时，代表该列的值为NULL。
- 二进制位的值为`0`时，代表该列的值不为NULL。
- 另外，**NULL 值列表必须用整数个字节的位表示（1字节8位）**，如果使用的二进制位个数不足整数个字节，则在字节的高位补 `0`。

==NULL 值列表也不是必须的。==当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了。



先来看**第一条记录**，第一条记录所有列都有值，不存在 NULL 值，所以用二进制来表示是酱紫的：

<img src="images/null值列表1.png" alt="img" style="zoom:50%;" />

但是 InnoDB 是用整数字节的二进制位来表示 NULL 值列表的，现在不足 8 位，所以要在高位补 0，最终用二进制来表示是酱紫的：

<img src="images/null值列表2.png" alt="img" style="zoom: 33%;" />

所以，对于第一条数据，NULL 值列表用十六进制表示是 0x00。

接下来看**第二条记录**，第二条记录 age 列是 NULL 值，所以，对于第二条数据，NULL值列表用十六进制表示是 0x04。

<img src="images/null值列表3.png" alt="img" style="zoom:33%;" />

我们把三条记录的 NULL 值列表都填充完毕后，它们的行格式是这样的：

<img src="images/null值列表5.png" alt="img" style="zoom: 33%;" />

==NULL 值列表也不是必须的。==当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了。



- **3. 记录头信息**

记录头信息中包含的内容很多，我就不一一列举了，这里说几个比较重要的：

- delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。
- next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。
- record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录



- **4. 记录的真实数据**

记录真实数据部分除了我们定义的字段，还有==三个隐藏字段==，分别为：row_id、trx_id、roll_pointer，我们来看下这三个字段是什么。

<img src="images/记录的真实数据.png" alt="img" style="zoom: 33%;" />

- row_id

如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。**row_id不是必需的**，占用 6 个字节。

- trx_id

事务id，表示这个数据是由哪个事务生成的。 **trx_id是必需的**，占用 6 个字节。

- roll_pointer

这条记录上一个版本的指针。**roll_pointer 是必需的**，占用 7 个字节。

如果你熟悉 MVCC 机制，你应该就清楚 trx_id 和 roll_pointer 的作用了，如果你还不知道 MVCC 机制，可以看完[这篇文章 (opens new window)](https://xiaolincoding.com/mysql/transaction/mvcc.html)，一定要掌握，面试也很经常问 MVCC 是怎么实现的。

### 4、varchar(n) 中 n 最大取值为多少？

**MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列**（不包括隐藏列和记录头信息，但包含[变长字段长度列表」和 「NULL 值列表」）**占用的字节长度加起来不能超过 65535 个字节。**

==也就是说，一行记录除了 TEXT、BLOBs类型的列，限制最大为 65535 字节，注意是一行的总长度，不是一列。==

varchar(n) 字段类型的 n 代表的是==最多存储的字符数量，并不是字节大小哦。==

==要算 varchar(n) 最大能允许存储的字节数，还要看数据库表的字符集，==因为字符集代表着，1个字符要占用多少字节，比如 ascii 字符集， 1 个字符占用 1 字节，那么 varchar(100) 意味着最大能允许存储 100 字节的数据。

==在UTF-8编码中:== —个中文等于三个字节，中文标点占三个字节。一个英文字符等于一个字节，英文标点占一个字节。

**1、单字段的情况**

前面我们知道了，一行记录最大只能存储 65535 字节的数据。

那假设数据库表只有一个 varchar(n) 类型的列且字符集是 ascii，在这种情况下， varchar(n) 中 n 最大取值是 65535 吗？

答案是不能，因为这个大小，**一行数据的最大字节数 65535，其实是包含「变长字段长度列表」和 「NULL 值列表」所占用的字节数的**。

### 5.行溢出后，MySQL 是怎么处理的？

==行溢出：一个页存不了一行数据==

MySQL 中磁盘和内存交互的基本单位是页，一个页的大小一般是 `16KB`，也就是 `16384字节`，而一个 varchar(n) 类型的列最多可以存储 `65532字节`，一些大对象如 TEXT、BLOB 可能存储更多的数据，这时一个页可能就存不了一条行记录。这个时候就会**发生行溢出，多的数据就会存到另外的「溢出页」中**。

**如果一个 [数据页] 存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页**。大致如下图所示。

<img src="images/行溢出.png" alt="img" style="zoom:33%;" />

==Compressed 和 Dynamic== 这两个行格式和 Compact 非常类似，主要的区别在于处理行溢出数据时有些区别。

这两种格式**采用完全的行溢出方式**，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中，看起来就像下面这样：

<img src="images/行溢出2.png" alt="img" style="zoom:33%;" />

### 总结（背诵）

**1、MySQL 的 NULL 值是怎么存放的？**

MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。

NULL值列表会==占用 1 字节空间==，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。

**2、MySQL 怎么知道 varchar(n) 实际占用数据的大小？**

MySQL 的 Compact 行格式中会用「变长字段长度列表」存储 变长字段实际占用的数据大小。

**3、varchar(n) 中 n 最大取值为多少？**

一行记录最大能存储 65535 字节的数据，但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。所以， 我们在算 varchar(n) 中 n 最大值时，需要减去这两个列表所占用的字节数。

**4、行溢出后，MySQL 是怎么处理的？**

如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。

Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。

Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。



## ==3.存储引擎了解吗？myisam和innodb区别==

所谓的**存储引擎**，说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法。MySQL 存储引擎有 MyISAM 、InnoDB、Memory，其中 InnoDB 是在 MySQL 5.5 之后成为默认的存储引擎，**索引和数据就是位于存储引擎中：**

<img src="images/1623727651911_20170928110355446.png" alt="img" style="zoom:80%;" />

虽然，MyISAM 的性能还行，各种特性也还不错（比如全文索引、压缩、空间函数等）。但是，MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。

**1.MYISAM不支持行级锁**

MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。

也就说，MyISAM 一锁就是锁住了整张表，这在并发写的情况下是多么滴憨憨啊！这也是为什么 InnoDB 在并发写的时候，性能更牛皮了！

**2.MYISAM不支持事务**

InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重读）隔离级别是可以大部分情况解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。

**4.是否支持数据库异常崩溃后的安全恢复**

MyISAM 不支持，而 InnoDB 支持。

使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log` 



## 3.什么是索引？

> 当你想查阅书中某个知识的内容，你会选择一页一页的找呢？还是在书的目录去找呢？傻瓜都知道时间是宝贵的，当然是选择在书的目录去找，找到后再翻到对应的页。书中的**目录**，就是充当**索引**的角色，方便我们快速查找书中的内容，所以索引是以空间换时间的设计思想。

- 那换到数据库中，索引的定义就是帮助存储引擎快速获取数据的==一种排序的数据结构==。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询表中数据。形象的说就是**索引是数据的目录**。
- 索引是==一个特殊的文件==(  InnoDB数据表上的索引是**表空间的一个组成部分**)，他们包含着对数据表里所有记录的引用指针，==需要占据物理空间，存储在磁盘中==，。

> 在创建表时，InnoDB 存储引擎会==自动==根据不同的场景选择不同的列作为索引：
>
> - 如果有主键，默认会使用主键作为聚簇索引的索引键（key）；
> - 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；
> - 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；
>
> 其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。**创建的主键索引和二级索引默认使用的是 B+Tree 索引**。





## 4.索引的优缺点？

**索引的优点**

- 可以大大==加快数据的检索速度==，这也是创建索引的最主要的原因。

**索引的缺点**

- ==需要占用物理空间==，数量越大，占用空间越大
- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；
- ==会降低表的增删改的效率==，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。



## ==5.MySQL有哪几种索引类型？==

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。
- 按「字段个数」分类：**单列索引、联合索引**。



## ==6.b+索引的存储和查询过程==

从数据结构的角度来看，MySQL 常见索引有 B+Tree 索引、HASH 索引、Full-Text 索引。

每一种存储引擎支持的索引类型不一定相同，我在表中总结了 MySQL 常见的存储引擎 InnoDB、MyISAM 和 Memory 分别支持的索引类型。

<img src="images/索引分类.drawio.png" alt="img" style="zoom:50%;" />

InnoDB 是在 MySQL 5.5 之后成为默认的 MySQL 存储引擎，B+Tree 索引类型也是 MySQL 存储引擎采用最多的索引类型。

为了让大家理解 ==B+Tree 索引的存储和查询的过程==，接下来我通过一个简单例子，说明一下 B+Tree 索引在存储数据中的具体实现。

### 通过主键索引查询数据的过程

**1、先创建一张商品表，id 为主键，如下：**

<img src="images/image-20230212152006719.png" alt="image-20230212152006719" style="zoom:80%;" />

商品表里，有这些行数据：

<img src="images/824c43b801c64e81acb0a9b042d50311.png" alt="img" style="zoom: 33%;" />

这些行数据，存储在 B+Tree 索引时是长什么样子的？

B+Tree 是一种多叉树，**叶子节点才存放索引和数据数据，非叶子节点只存放索引**，而且每个节点里的数据是**按主键顺序存放**的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，==形成一个双向链表==。

主键索引的 B+Tree 如图所示（图中叶子节点之间我画了单向链表，但是实际上是双向链表，原图我找不到了，修改不了，偷个懒我不重画了，==大家脑补成双向链表就行==）：

<img src="images/btree.drawio-16761863492555.png" alt="主键索引 B+Tree" style="zoom:50%;" />



**2、通过主键查询商品数据的过程**

比如，我们执行了下面这条查询语句：

<img src="images/image-20230212152115237.png" alt="image-20230212152115237" style="zoom:80%;" />

> 这条语句使用了主键索引查询 id 号为 5 的商品。查询过程是这样的，B+Tree 会自顶向下逐层进行查找：
>
> - 将 5 与根节点的索引数据 (1，10，20) 比较，5 在 1 和 10 之间，所以根据 B+Tree的搜索逻辑，找到第二层的索引数据 (1，4，7)；
> - 在第二层的索引数据 (1，4，7)中进行查找，因为 5 在 4 和 7 之间，所以找到第三层的索引数据（4，5，6）；
> - 在叶子节点的索引数据（4，5，6）中进行查找，然后我们找到了索引值为 5 的行数据。

==数据库的索引和数据都是存储在硬盘的，我们可以把读取一个节点当作一次磁盘 I/O 操作==。那么上面的整个查询过程一共经历了 3 个节点，也就是进行了 3 次 I/O 操作。

B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从==千万级==的表查询目标数据最多需要 3-4 次磁盘 I/O，所以**B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。**



### **通过二级索引查询商品数据的过程**

主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：

- 主键索引的 B+Tree 的==叶子节点存放的是实际数据==，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的==叶子节点存放的是主键值==，而不是实际数据。

这里将前面的商品表中的 **product_no （商品编码）字段设置为二级索引**，那么二级索引的 B+Tree 如下图（图中叶子节点之间我画了单向链表，但是实际上是双向链表，原图我找不到了，修改不了，偷个懒我不重画了，大家脑补成双向链表就行）。

<img src="images/二级索引btree.drawio.png" alt="二级索引 B+Tree" style="zoom:50%;" />

==其中非叶子的 key 值是 product_no（图中橙色部分），叶子节点存储的数据是主键值（图中绿色部分）。==

如果我用 product_no 二级索引查询商品，如下查询语句：

<img src="images/image-20230212152514882.png" alt="image-20230212152514882" style="zoom:80%;" />

会先检二级索引中的 B+Tree 的索引值（商品编码，product_no），找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。**这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据**。如下图（图中叶子节点之间我画了单向链表，但是实际上是双向链表，原图我找不到了，修改不了，偷个懒我不重画了，大家脑补成双向链表就行）：

<img src="images/回表.drawio.png" alt="回表" style="zoom: 50%;" />

不过，当查询的数据是能在二级索引的 B+Tree 的叶子节点里查询到，这时就不用再查主键索引查，比如下面这条查询语句：

<img src="images/image-20230212152557177.png" alt="image-20230212152557177" style="zoom:80%;" />

**这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据**。



## ==7.为什么 MySQL InnoDB 选择 B+tree 作为索引的数据结构？==

> 要设计一个 MySQL 的索引数据结构，不仅仅考虑==数据结构增删改的时间复杂度==，更重要的是要==考虑磁盘 I/0 的操作次数==。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在==尽可能少的磁盘 I/0 的操作次数内完成查询==。
>
> ==树的高度决定于磁盘  I/O 操作的次数==，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能

***1、B+Tree vs B Tree***

- **B+树的磁盘读写代价更低：**B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，使得B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。

- **B+树范围查询效率高：**B+Tree 叶子节点采用的是双链表连接，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化

***2、B+Tree vs Hash***

Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。

==但是 Hash 表不适合做范围查询，它更适合做等值的查询==，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。

***3、B+Tree vs 二叉树***

二叉树: 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度)，并且IO代价高。

对于有 N 个叶子节点的 B+Tree，其搜索复杂度为`O(logdN)`，其中 d 表示节点允许的最大子节点个数为 d 个。在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。

而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 `O(logN)`，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。

**4、B+Tree vs 红黑树**

红黑树：树的高度随着数据量增加而增加，IO代价高。



## 7-2. 红黑树，B树，B+树

==**1、红黑树**==

我们前面介绍了2-3树，可以看到2-3树能保证在插入元素之后，树依然保持平衡状态，它的最坏情况下所有子结点都是2-结点，树的高度为**lgN**,相比于我们普通的二叉查找树，最坏情况下树的高度为**N**，确实保证了最坏情况下的时间复杂度，但是2-3树实现起来过于复杂，所以我们介绍一种2-3树思想的简单实现：红黑树。

红黑树主要是对2-3树进行编码，红黑树背后的**基本思想**是用**标准的二叉查找树**(完全由2-结点构成)和一些**额外的信息**(替换3-结点)来表示2-3树。我们将树中的链接分为两种类型：

- **红链接：**将两个2-结点连接起来构成一个3-结点； 

- **黑链接：**则是2-3树中的普通链接。

确切的说，我们将3-结点表示为由由一条**左斜**的红色链接(两个2-结点其中之一是另一个的左子结点)相连的两个2-结点。**这种表示法的一个优点是，我们无需修改就可以直接使用标准的二叉查找树的get方法。**

<img src="images/image-20230804143241800.png" alt="image-20230804143241800" style="zoom:50%;" />



==**2、B树**==

前面我们已经学习了二叉查找树、2-3树以及它的实现红黑树。2-3树中，一个结点做多能有两个key，它的实现红黑树中使用对链接染色的方式去表达这两个key。接下来我们学习另外一种树型结构B树，这种数据结构中，一**个结点允许多于两个key的存在**。

B树是一种**树状数据结构**，它能够存储数据、对其进行排序并允许以**O(logn)**的时间复杂度进行查找、顺序读取、插入和删除等操作。

B树中允许一个结点中包含多个key，可以是3个、4个、5个甚至更多，并不确定，需要看具体的实现。现在我们选择一个参数M，来构造一个B树，我们可以把它称作是M阶的B树，那么该树会具有如下特点：

- 每个结点最多有M-1个key，并且以升序排列；
- 每个结点最多能有M个子结点；
- 根结点至少有两个子结点；

![image-20230131184234723](images/image-20230131184234723.png)

在实际应用中B树的阶数一般都比较大（通常大于100），所以，即使存储大量的数据，B树的高度仍然比较小，这样在某些应用场景下，就可以体现出它的优势



==**3、B+树**==

B+树是对B树的一种变形树，它与B树的差异在于：

1. 非叶结点仅具有**索引**作用，也就是说，非叶子结点只存储key，不存储value；

2. 树的所有叶结点构成一个**有序链表**，可以按照key排序的次序遍历全部数据。

**B+树存储数据**

若参数M选择为5，那么每个结点最多包含4个键值对，我们以5阶B+树为例，看看B+树的数据存储。

<img src="images/image-20230804145805301.png" alt="image-20230804145805301" style="zoom:67%;" />

<img src="images/image-20230804145817455.png" alt="image-20230804145817455" style="zoom:80%;" />





##  8.按物理存储分类

从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。

这两个区别在前面也提到了：

- 主键索引的 B+Tree 的**叶子节点存放的是实际数据**，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的**叶子节点存放的是主键值**，而不是实际数据。

所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是**覆盖索引**。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是**回表**。



## ==9.按字段特性分类==

从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引。

**主键索引**

主键索引就是==建立在主键字段上的索引==，通常在创建表的时候一起创建，==一张表最多只有一个主键索引==。在创建表时，创建主键索引的方式如下：

**唯一索引**

唯一索引==建立在 UNIQUE 字段上的索引==，一张表可以==有多个唯一索引==，索引列的值必须唯一，但是允许有空值。在创建表时，创建唯一索引的方式如下：

**普通索引**

普通索引就是==建立在普通字段上的索引==，既不要求字段为主键，也不要求字段为 UNIQUE。

**前缀索引**

前缀索引是==指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引==，

前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。



## 10. 按字段个数分类

从字段个数的角度来看，索引分为单列索引、联合索引（复合索引）。

- 建立在单列上的索引称为单列索引，比如主键索引；
- 建立在**多列上的**索引称为联合索引；

### ==联合索引，最左匹配==

**联合索引**：通过将==多个字段组合成一个索引==，该索引就被称为联合索引。

比如，将商品表中的 **product_no 和 name** 字段组合成联合索引`(product_no, name)`，创建联合索引的方式如下：

<img src="images/image-20230212154903060.png" alt="image-20230212154903060" style="zoom:80%;" />

联合索引`(product_no, name)` 的 B+Tree 示意图如下（图中叶子节点之间我画了单向链表，但是实际上是双向链表，原图我找不到了，修改不了，偷个懒我不重画了，大家脑补成双向链表就行）。

<img src="images/联合索引.drawio.png" alt="联合索引" style="zoom:50%;" />

可以看到，联合索引的**非叶子节点用两个字段的值作为 B+Tree 的 key 值**。当在联合索引查询数据时，先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。

也就是说，联合索引查询的 B+Tree 是**先按 product_no 进行排序**，然后再 product_no 相同的情况再按 name 字段排序。

因此，使用联合索引时，存在**最左匹配原则（在写SQL时就要注意）**，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效。

> 比如，如果创建了一个 `(a, b, c)` 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：
>
> - where a=1；
> - where a=1 and b=2 and c=3；
> - where a=1 and b=2；
>
> 需要注意的是，查询时，=和in可以乱序，比如a = 1 and b= 2 and c = 3建立(a,b,c)索引可以任意顺序，**mysql的查询优化器会帮你优化成索引可以识别的形式。**
>
> 但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:
>
> - where b=2；
> - where c=3；
> - where b=2 and c=3；
>
> 上面这些查询条件之所以会失效，是因为`(a, b, c)` 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，**b 和 c 是全局无序，局部相对有序的**，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。

> 我这里举联合索引（a，b）的例子，该联合索引的 B+ Tree 如下（图中叶子节点之间我画了单向链表，但是实际上是双向链表，原图我找不到了，修改不了，偷个懒我不重画了，大家脑补成双向链表就行）。
>
> <img src="images/联合索引案例.drawio.png" alt="img" style="zoom: 33%;" />
>
> 可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8），而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。因此，直接执行`where b = 2`这种查询条件没有办法利用联合索引的，**利用索引的前提是索引里的 key 是有序的**。
>
> 只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候，b 的值为（7，8），这时就是有序的，这个有序状态是局部的，因此，执行`where a = 2 and b = 7`是 a 和 b 字段能用到联合索引的，也就是联合索引生效了。



###  ==联合索引范围查询==

> 总结背诵：综上所示，**联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配。（也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引）。注意，对于 >=、<=、BETWEEN、like 前缀匹配，的范围查询，并不会停止匹配，前面我也用了四个例子说明了**。



依然是上面（a, b ) 联合索引的例子

联合索引有一些特殊情况，**并不是查询过程使用了联合索引查询，就代表联合索引中的所有字段都用到了联合索引进行索引查询**，也就是可能存在部分字段用到联合索引的 B+Tree，部分字段没有用到联合索引的 B+Tree 的情况。==这种特殊情况就发生在范围查询。==

联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。**也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引**。

范围查询有很多种，那到底是哪些范围查询会导致联合索引的最左匹配原则会停止匹配呢？

接下来，举例几个范围查例子。



> Q1: `select * from t_table where a > 1 and b = 2`，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？

由于联合索引==（二级索引）==是先按照 a 字段的值排序的，所以符合 a > 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 a > 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a > 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。

**但是在符合 a > 1 条件的二级索引记录的范围里，b 字段的值是无序的**。比如前面图的联合索引的 B+ Tree 里，下面这三条记录的 a 字段的值都符合 a > 1 查询条件，而 b 字段的值是无序的：

- a 字段值为 5 的记录，该记录的 b 字段值为 8；
- a 字段值为 6 的记录，该记录的 b 字段值为 10；
- a 字段值为 7 的记录，该记录的 b 字段值为 5；

因此，我们不能根据查询条件 b = 2 来进一步减少需要扫描的记录数量（b 字段无法利用联合索引进行索引查询的意思）。

所以在执行 Q1 这条查询语句的时候，对应的扫描区间是 (2, + ∞)，形成该扫描区间的边界条件是 a > 1，与 b = 2 无关。

因此，**Q1 这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引**。

我们也可以在==执行计划中的 key_len 知道这一点==，在使用联合索引进行查询的时候，通过 key_len 我们可以知道优化器具体使用了多少个字段的搜索条件来形成扫描区间的边界条件。

举例个例子 ，a 和 b 都是 int 类型且不为 NULL 的字段，那么 Q1 这条查询语句执行计划如下，可以看到 key_len 为 4 字节（如果字段允许为 NULL，就在字段类型占用的字节数上加 1，也就是 5 字节），说明只有 a 字段用到了联合索引进行索引查询，而且可以看到，即使 b 字段没用到联合索引，key 为 idx_a_b，说明 Q1 查询语句使用了 idx_a_b 联合索引。

![img](images/q1.png)

通过 Q1 查询语句我们可以知道，a 字段使用了 > 进行范围查询，联合索引的最左匹配原则在遇到 a 字段的范围查询（ >）后就停止匹配了，因此 b 字段并没有使用到联合索引。





> Q2: `select * from t_table where a >= 1 and b = 2`，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？

Q2 和 Q1 的查询语句很像，**唯一的区别就是 a 字段的查询条件「大于等于」。**

由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 >= 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 >= 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a>= 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。

虽然在符合 a>= 1 条件的二级索引记录的范围里，b 字段的值是「无序」的，**但是对于符合 a = 1 的二级索引记录的范围里，b 字段的值是「有序」的**（因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下，再按照 b 字段的值进行排序）。

于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 a 字段值为 1 时，可以通过 b = 2 条件减少需要扫描的二级索引记录范围（b 字段可以利用联合索引进行索引查询的意思）。也就是说，从符合 a = 1 and b = 2 条件的第一条记录开始扫描，而不需要从第一个 a 字段值为 1 的记录开始扫描。

所以，**Q2 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询**。

我们也可以在==执行计划中的 key_len 知道这一点==。执行计划如下，可以看到 key_len 为 8 字节，说明优化器使用了 2 个字段的查询条件来形成扫描区间的边界条件，也就是 a 和 b 字段都用到了联合索引进行索引查询。

![img](images/q2.png)

通过 Q2 查询语句我们可以知道，虽然 a 字段使用了 >= 进行范围查询，但是联合索引的最左匹配原则并没有在遇到 a 字段的范围查询（ >=）后就停止匹配了，b 字段还是可以用到了联合索引的。



> Q3: `SELECT * FROM t_user WHERE name like 'j%' and age = 22`，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？

由于联合索引（二级索引）是先按照 name 字段的值排序的，所以前缀为 ‘j’ 的 name 字段的二级索引记录都是相邻的， 于是在进行索引扫描的时候，可以定位到符合前缀为 ‘j’ 的 name 字段的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录的 name 前缀不为 ‘j’ 为止。

所以 a 字段可以在联合索引的 B+Tree 中进行索引查询，形成的扫描区间是['j','k')。注意， j 是闭区间。如下图：

<img src="images/q4-1.drawio.png" alt="img" style="zoom: 67%;" />

虽然在符合前缀为 ‘j’ 的 name 字段的二级索引记录的范围里，age 字段的值是「无序」的，**但是对于符合 name = j 的二级索引记录的范围里，age字段的值是「有序」的**（因为对于联合索引，是先按照 name 字段的值排序，然后在 name 字段的值相同的情况下，再按照 age 字段的值进行排序）。

于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 name 字段值为 ‘j’ 时，==可以通过 age = 22 条件减少需要扫描的二级索引记录范围（age 字段可以利用联合索引进行索引查询的意思）==。也就是说，从符合 `name = 'j' and age = 22` 条件的第一条记录时开始扫描，而不需要从第一个 name 为 j 的记录开始扫描 。如下图的右边：

<img src="images/q4-2.drawio.png" alt="img" style="zoom:50%;" />

所以，**Q4 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询**。



### ==索引下推==

- ==有了索引下推优化，可以在减少回表次数==
- ==在InnoDB中只针对二级索引有效==

现在我们知道，对于联合索引（a, b），在执行 `select * from table where a > 1 and b = 2` 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？

- 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。
- 而 MySQL 5.6 引入的**索引下推优化**（index condition pushdown)， **可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**。

当你的查询语句的执行计划里，出现了 Extra 为 `Using index condition`，那么说明使用了索引下推的优化。



### ==索引区分度==

另外，建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中**建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到**。

区分度就是某个字段 column 不同值的个数「除以」表的总行数，计算公式如下：

<img src="images/区分度.png" alt="区分度计算公式" style="zoom:50%;" />



###  ==联合索引进行查询优化==

这里出一个题目，针对针对下面这条 SQL，你怎么通过索引来提高查询效率呢？

```sql
select * from order where status = 1 order by create_time asc
```

有的同学会认为，单独给 status 建立一个索引就可以了。

但是更好的方式给 status 和 create_time 列建立一个联合索引，因为这样可以**避免 MySQL 数据库发生文件排序。**

因为在查询时，如果只用到 status 的索引，但是这条语句还要对 create_time 排序，这时就要用文件排序 filesort，也就是在 SQL 执行计划中，Extra 列会出现 Using filesort。

所以，要利用索引的有序性，在 status 和 create_time 列建立联合索引，这样根据 status 筛选后的数据就是按照 create_time 排好序的，避免在文件排序，提高了查询效率。





## 11.什么时候需要索引？

- 字段有唯一性限制的，比如商品编码；
- 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。



##  12.什么时候不需要创建索引？

- **`WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段**，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
- **字段中存在大量重复数据，不需要创建索引，比如性别字段**，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- **表数据太少的时候**，不需要创建索引；
- **经常更新的字段不用创建索引，**比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的



## ==13.如何优化索引？==

这里说一下几种常见优化索引的方法：

- 前缀索引优化；
- 覆盖索引优化；
- 主键索引最好是自增的；
- 索引最好设置为 NOT NULL
- 防止索引失效；

**1、前缀索引优化**

前缀索引顾名思义就是==使用某个字段中字符串的前几个字符建立索引==，那我们为什么需要使用前缀来建立索引呢？

使用前缀索引是==为了减小索引字段大小，可以增加一个索引页中存储的索引值，==有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。

不过，前缀索引有一定的局限性，例如：

- order by 就无法使用前缀索引；
- 无法把前缀索引用作覆盖索引；

**2、覆盖索引优化**

覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。

假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？

**我们可以建立一个联合索引，**即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。

所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。



**3、主键索引最好是自增的**

==我们在建表的时候，都会默认将主键索引设置为自增的，具体为什么要这样做呢？又什么好处？==

==主要目的：因为自增主键是连续的，可以提高插入数据的效率，减少页分裂的次数==

InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。

**如果我们使用自增主键**，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次**插入一条新记录，都是追加操作，不需要重新移动数据**，因此这种插入数据的方法效率非常高。

**如果我们使用非自增主键**，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为**页分裂**。**页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率**。因此，在使用 InnoDB 存储引擎时，如果没有特别的业务需求，建议使用自增字段作为主键。

==另外，主键字段的长度不要太大==，因为**主键字段长度越小，意味着二级索引的叶子节点越小（二级索引的叶子节点存放的数据是主键值），这样二级索引占用的空间也就越小**。

> 举个例子，假设某个数据页中的数据是1、3、5、9，且数据页满了，现在准备插入一个数据7，则需要把数据页分割为两个数据页：
>
> <img src="images/页分裂.png" alt="img" style="zoom: 25%;" />
>
> 出现页分裂时，需要将一个页的记录移动到另外一个页，性能会受到影响，同时页空间的利用率下降，造成存储空间的浪费。
>
> 而如果记录是顺序插入的，例如插入数据11，则只需开辟新的数据页，也就不会发生页分裂：
>
> <img src="images/开辟新页.png" alt="img" style="zoom:25%;" />



**4、索引最好设置为 NOT NULL**

为了更好的利用索引，索引列要设置为 NOT NULL 约束。有两个原因：

- ==第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，==因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。

- ==第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，==所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么[行格式 (opens new window)](https://xiaolincoding.com/mysql/base/row_format.html#innodb-行格式有哪些)中**至少会用 1 字节空间存储 NULL 值列表**，如下图的紫色部分：

  <img src="images/COMPACT.drawio-167620467178624.png" alt="img" style="zoom: 33%;" />

**5、防止索引失效**

用上了索引并不意味着查询的时候会使用到索引，所以我们心里要清楚有哪些情况会导致索引失效，从而**避免写出索引失效的查询语句**，否则这样的查询效率是很低的。







## ==13.通过执行计划explain判断是否使用索引==

如下图，就是一个没有使用索引，并且是一个全表扫描的查询语句。

<img src="images/798ab1331d1d6dff026e262e788f1a28.png" alt="img" style="zoom: 80%;" />

对于执行计划，参数有：

- possible_keys 字段表示可能用到的索引；
- ==key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；==
- ==key_len 表示索引的长度；==
- rows 表示扫描的数据行数。
- **type 表示数据扫描类型，我们需要重点看这个。**

**type 字段**就是描述了找到所需数据时**使用的扫描方式**是什么，常见扫描类型的**执行效率从低到高的顺序为**：

- All（全表扫描）；
- index（全索引扫描）；
- range（索引范围扫描）；
- ref（非唯一索引扫描）；
- eq_ref（唯一索引扫描）；
- const（结果只有一条的主键或唯一索引扫描）。

> 在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，==要尽量避免全表扫描和全索引扫描。==
>
> range 表示采用了索引范围扫描，一般在 where 子句中使用 < 、>、in、between 等关键词，只检索给定范围的行，属于范围查找。==从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式==。
>
> ref 类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀，返回数据返回可能是多条。因为虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但**它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。**
>
> **eq_ref 类型是使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。**比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref。
>
> const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id=1。
>
> 需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，**const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中**

**除了关注 type，我们也要关注 extra 显示的结果。**

这里说几个重要的参考指标：

- Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。
- Using temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。
- Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错。



## ==14.索引失效的情况有哪些？==

**4种情况：**

- **使用左模糊 或者左右模糊匹配的时候**。

  也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。

- **当在查询条件中对索引列做了计算、函数、类型转换操作**，这些情况下都会造成索引失效；

  - 计算：原因跟对索引使用函数差不多。如`explain select * from t_user where id + 1 = 10;`
  - 使用函数：因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。如 `select * from t_user where length(name)=6;`
  - 使用隐式类型转换：MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。例如phone存的是字符串，但我们查的时候写的是`select * from t_user where phone = 1300000001;`这个语句会实际变成`select * from t_user where CAST(phone AS signed int) = 1300000001;` 底==层相当于对索引使用了函数==

- **联合索引要遵循最左匹配原则，**也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。

- **在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。**







## ==15.说一说索引的底层实现？==

**Hash索引**

基于哈希表实现，==只有精确匹配索引所有列的查询才有效==，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码(hash code)，并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。

<img src="images/image-20230212205617858.png" alt="image-20230212205617858" style="zoom:50%;" />

**B-Tree索引**

B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。

<img src="images/image-20230212205706175.png" alt="image-20230212205706175" style="zoom:50%;" />

**B+Tree索引**

是B-Tree的改进版本，**数据都在叶子节点上，非叶子节点只存索引值**，并且增加了顺序访问指针，**叶子节点通过双向链表链接起来**。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。



## ==16.讲一讲聚簇索引与非聚簇索引?==

- 主键索引的 B+Tree 的==叶子节点存放的是实际整行数据==，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；也被称之为聚簇索引，即将数据存储与索引放到了一块，找到索引也就找到了数据。
- 二级索引的 B+Tree 的==叶子节点存放的是主键值==，而不是实际数据。
- 通常情况下，**主键索引（聚簇索引）查询只会查一次，而非主键索引(非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可**

## 17.非聚簇索引一定会回表查询吗?

不一定，这涉及到查询的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。也就是说在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。不需要回表。

举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select score from studentwhere score > 90的查询时，在索引的叶子节点上，已经包含了score信息，不会再次进行回表查询。





## ==18. 如何创建索引？sql语句==

**1、自动创建索引：**

当在表中定义一个primary key 或者unique时，MySQL数据库会自动创建一个对应的主键索引或者是唯一索引。

> ==对于主键索引：是一定存在的==
>
> 在创建表时，InnoDB 存储引擎会自动根据不同的场景选择不同的列作为索引：
>
> - 如果有主键，默认会使用主键作为聚簇索引的索引键（key）；
> - 如果没有主键，就选择第一个**非空唯一列**作为聚簇索引的索引键（key）；
> - 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；
>
> 其它索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。**创建的主键索引和二级索引默认使用的是 B+Tree 索引**。

**2、手动创建索引：**

==1、建立表时同步创建索引==

- 单列索引；

  - 主键索引（一般会默认给你创建的，在字段属性那里指明主键即可）

    ```sql
    CREATE TABLE table_name  (  #不用写，在字段指定即可
      ....
      PRIMARY KEY [index_name](column_name)  #不指定索引名称，就默认是列名
    );
    ```

  - 唯一索引；（非空是在创建字段的时候指定）

    ```sql
    CREATE TABLE table_name  (
      ....
      UNIQUE KEY [index_name](column_name) 
    );
    # 
    CREATE UNIQUE INDEX index_name ON table_name(column_name); 
    ```

  - 前缀索引；

    ```sql
    CREATE TABLE table_name(
        ....
        INDEX [index_name](column_name(length))
    );
    # 
    CREATE INDEX index_name ON table_name(column_name(length)); 
    ```

  - 普通索引；

    ```sql
    CREATE TABLE table_name  (
      ....
      INDEX [index_name](column_name) 
    );
    # 
    CREATE INDEX index_name ON table_name(column_name); 
    ```

- 联合索引；

  - 就是前面的普通索引，只是有多个字段而言；

    ```sql
    CREATE TABLE table_name  (
      ....
      INDEX index_product_no_name (product_no, name) 
    );
    # 
    CREATE INDEX index_product_no_name ON product(product_no, name);
    ```

==2、在表建好了之后创建，简言之就是两种==

- 使用**ALTER TABLE ...... ADD ......**命令去增加索引。
- 使用**CREATE INDEX ...... ON ......**命令创建。

<img src="images/image-20230212212205453.png" alt="image-20230212212205453" style="zoom:80%;" />

<img src="images/image-20230212212219625.png" alt="image-20230212212219625" style="zoom:80%;" />





## ==19.创建索引时需要注意什么？==

- **非空字段：**索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化。NULL 值是一个没意义的值，但是它会占用物理空间
- **主键索引最好是自增的**：可以提高插入数据的效率，减少页分裂的次数。
- **索引字段越小越好**: 数据库的数据存储以页为单位，一页存储的数据越多，一次lO操作获取的数据越大效率越高。
- **对于字符类型的索引，尽量使用前缀索引。**可以减少索引占用的存储空间，提升查询效率。
- **对于联合索引，取值索引区分度大的字段在前面。**最左匹配原则在这里。



## 20.使用索引查询一定能提高查询的性能吗?

**通常通过索引查询数据比全表扫描要快。**但是我们也必须注意到它的代价。



# 三、Mysql事务



## 21.什么是数据库事务?

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位。事务是逻辑上的一组操作，要么都执行，要么都不执行。



## ==22.介绍一下事务具有的四个特征==

事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。不过并不是所有的引擎都能支持事务，比如 MySQL 原生的 MyISAM 引擎就不支持事务，也正是这样，所以大多数 MySQL 的引擎都是用 InnoDB。

- **原子性 （Atomicity）**事务是数据库的逻辑工作单位，一个事务中的所有操作，要么全部完成，要么全部不完成，
- **持久性（Durability）**，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。
- **隔离性（Isolation）**一个事务的执行不受其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。
- **一致性（Consistency）**事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。

**InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？**

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过==MVCC（多版本并发控制） 或锁机制==来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；==ADIC==

这次将**重点介绍事务的隔离性**，这也是面试时最常问的知识的点。





## 23.什么是脏读?幻读?不可重复读?

MySQL 服务端在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题。

**1、脏读：** ==事务A读取了事务B更新但未提交的数据，然后B回滚操作，那么A读取到的数据是脏数据==

**2、不可重复读：**==在一个事务内多次读取同一个数据，出现前后两次读到的数据不一样的情况==。事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

**3、幻读：** ==在一个事务内多次查询某个符合查询条件的「记录数量」，出现前后两次查询到的记录数量不一样的情况==。

==不可重复读侧重于单条记录修改、删除==，==幻读侧重于查询的记录数量（多了或少量行)==，==脏读是一个事务回滚影响另外一个事务。==

这三个现象的严重性排序如下：

<img src="images/d37bfa1678eb71ae7e33dc8f211d1ec1.png" alt="图片" style="zoom:50%;" />



## ==24.说一下MySQL的四种隔离级别==

==SQL 标准（注意到是sql提出的哦，其他数据库厂商是实现）==提出了四种隔离级别来解决**并发事务的三大问题**，隔离级别越高，性能效率就越低：

- **读未提交（read uncommitted）**，指一个事务还没提交时，它做的变更就能被其他事务看到；会导致脏读、不可重复读、幻读。
- **读已提交（read committed）**，指一个事务提交之后，它做的变更才能被其他事务看到；会导致不可重复读、幻读。
- **可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。==会导致幻读。==**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（serializable ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

<img src="images/4e98ea2e60923b969790898565b4d643.png" alt="图片" style="zoom:50%;" />

> 不同的数据库厂商对 SQL 标准中规定的 4 种隔离级别的支持不一样，有的数据库只实现了其中几种隔离级别，**我们讨论的 MySQL 虽然支持 4 种隔离级别，但是与SQL 标准中规定的各级隔离级别允许发生的现象却有些出入**。
>
> **主要在【可重复读】下的区别：MySQL 在「可重复读」隔离级别下，可以==很大程度上避免幻读==现象的发生（注意是很大程度避免，并不是彻底避免）**，所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能。





## ==25.MySQL是如何实现四种隔离级别的？==

- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
- 对于「串行化」隔离级别的事务来说，通过加**读写锁**的方式来避免并行访问；
- 对于「读已提交」和「可重复读」隔离级别的事务来说，它们是通过 **Read View 来实现的，它们的区别在于创建 Read View 的时机不同**，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「**读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。**【其中，针对当前读的话，采用的是next-key lock（记录锁+间隙锁）】

注意，执行「开始事务」命令，并不意味着启动了事务。在 MySQL 有两种开启事务的命令，分别是：

- 第一种：begin/start transaction 命令；
  - 执行了 begin/start transaction 命令后，并不代表事务启动了。只有在执行了增删查改操作的 SQL 语句，才是事务真正启动的时机；
- 第二种：start transaction with consistent snapshot 命令；
  - 马上启动事务



## ==26.什么是MVCC？实现原理？==

**MVCC，即多版本并发控制，指的是维持一个数据的多个版本。MVCC的实现，是通过保存数据在某个时间点的快照来实现的。**根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

MVCC的实现原理主要通过==版本链（行格式中两个隐藏字段 ）==、==undo日志==、==Read View== 来实现的

**一、版本链**

​		是由InnoDB行格式中，那两个隐藏字段trx_id、roll_pointer对同一个数据不同版本形成的链表。

<img src="images/image-20230213171541451.png" alt="image-20230213171541451" style="zoom: 67%;" />

- ==trx_id==，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- ==roll_pointer==，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 **undo 日志**中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。
- 两者就会对该行数据的修改会产生多个版本，然后通过回滚指针（roll_pointer），连成一个链表。

<img src="images/f595d13450878acd04affa82731f76c5.png" alt="图片" style="zoom:50%;" />

**二、Read View**

大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。**ReadView有四个重要的字段：**

<img src="images/readview结构.drawio.png" alt="img" style="zoom:50%;" />

- m_ids ：指的是在创建 Read View 时，当前数据库中**「活跃事务」的事务 id 列表**。
- min_trx_id ：指的是在创建 Read View 时，当前数据库中**「活跃事务」中事务 id 最小的事务**，也就是 m_ids 的最小值。
- max_trx_id ：是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1；
- creator_trx_id ：**创建该 Read View 的事务的事务 id**

在创建 Read View 后，我们可以将数据库所有记录中的 trx_id 划分这三种情况：

<img src="images/ReadView.drawio-16762804807605.png" alt="img" style="zoom:67%;" />

**一个事务去访问记录**的时候，除了自己的更新记录总是可见之外，还有这几种情况：

- 如果某条记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对**当前事务可见**。
- 如果某条记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录**对当前事务不可见**。

- 如果某条记录的 trx_id 值在 Read View 的 `min_trx_id` 和 `max_trx_id` 之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对**当前事务不可见**。然后会沿着 **undo log 链条往下找旧版本的记录**，直到找到 trx_id 「小于」事务 的 Read View 中的 min_trx_id 值的第一条记录。
  - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对**当前事务可见**。



## ==27.MySQL的可重复读完全解决了幻读吗？mysql的可重复读如何实现？==

SQL标准提出的【可重复读】是会导致幻读的，但MySQL在实现该隔离级别时却可以很大程度避免幻读，他是如何做到的呢？

首先select语句分为两种：分两种的原因在于解决幻读的方式不一样。

- **快照读**（普通 select 语句）

- **当前读（锁定读）**（select ... for update 等语句），每次执行的时候会去读取最新的数据。

  > - MySQL 里除了普通查询是快照读，其他都是当前读，比如 update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。



**针对快照读：**是通过 MVCC 方式解决了幻读。

> 由 **MVCC**（多版本并发控制）实现的，实现的方式是开始事务后（执行 begin 语句后），在执行第一个查询语句后，会创建一个 Read View，**后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的**，即使中途有其他事务插入了新纪录，是查询不出来这条数据的，所以就很好了避免幻读问题。

**针对当前读：**是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。

> 由于`select ... for update` 这种查询语句是当前读，每次执行的时候都是读取最新的数据，这样就一定会造成幻读现象！！
>
> **Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁，并与记录锁联合使用，形成next-key lock** 。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。直到锁住的事务完成了提交，其他事务才可以进行插入数据。



==幻读被完全解决了吗？==

上诉两种情况可以很大程度避免幻读，但是还是没有能完全解决幻读。

我举例一个可重复读隔离级别发生幻读现象的场景。

- T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。
- T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
- T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。

**要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。





## ==28.Read View 在 MVCC 里如何工作的？==

ReadView在【可重复读】下：**是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View**。

ReadView在【读提交】下：**是在每次读取数据时，都会生成一个新的 Read View**

==以在【可重复读】为例：==

假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，那这两个事务创建的 Read View 如下：

<img src="images/事务ab的视图-new.png" alt="img" style="zoom:50%;" />

事务 A 和 事务 B 的 Read View 具体内容如下：

- 在事务 A 的 Read View 中，它的事务 id 是 51，由于它是第一个启动的事务，所以此时活跃事务的事务 id 列表就只有 51，活跃事务的事务 id 列表中最小的事务 id 是事务 A 本身，下一个事务 id 则是 52。
- 在事务 B 的 Read View 中，它的事务 id 是 52，由于事务 A 是活跃的，所以此时活跃事务的事务 id 列表是 51 和 52，**活跃的事务 id 中最小的事务 id 是事务 A**，下一个事务 id 应该是 53。

接着，在可重复读隔离级别下，事务 A 和事务 B 按顺序执行了以下操作：

- 事务 B 读取小林的账户余额记录，读到余额是 100 万；
- 事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务；
- 事务 B 读取小林的账户余额记录，读到余额还是 100 万；
- 事务 A 提交事务；
- 事务 B 读取小林的账户余额记录，读到余额依然还是 100 万；

接下来，跟大家具体分析下。

事务 B 第一次读小林的账户余额记录，在找到记录后，它会先看这条记录的 trx_id，此时**发现 trx_id 为 50，比事务 B 的 Read View 中的 min_trx_id 值（51）还小，这意味着修改这条记录的事务早就在事务 B 启动前提交过了，所以该版本的记录对事务 B 可见的**，也就是事务 B 可以获取到这条记录。

接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务），将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成**版本链**，如下图：

<img src="images/事务ab的视图2.png" alt="img" style="zoom:50%;" />

你可以在上图的「记录的字段」看到，由于事务 A 修改了该记录，以前的记录就变成旧版本记录了，于是最新记录和旧版本记录通过链表的方式串起来，而且最新记录的 trx_id 是事务 A 的事务 id（trx_id = 51）。

然后事务 B 第二次去读取该记录，**发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录**，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。

最后，当事物 A 提交事务后，**由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录**。

就是通过这样的方式实现了，「可重复读」隔离级别下在事务期间读到的记录都是事务启动前的记录。



## ==29.介绍一下MySQL的事务日志？==

**undo log（回滚日志）**：是==Innodb==存储引擎层生成的日志，实现了事务中的**原子性**，主要**用于事务回滚和 MVCC**。==——原子性==

**redo log（重做日志）**：是 ==Innodb== 存储引擎层生成的日志，实现了事务中的**持久性**，主要**用于掉电等故障恢复**；mysql挂了或者宕机之后，innodb依赖redo log恢复数据，保证了数据的==持久性。==

- redo log采用循环重写的方式，内部有两个日志文件，写满第一个后，去写第二个。但两个文件总会满的啊，此时就会有一个问题。
-  **redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞**（*因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要*），此时**会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）**，然后 MySQL 恢复正常运行，继续执行新的更新操作。所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。
- <img src="images/重做日志文件组写入过程.drawio.png" alt="重做日志文件组写入过程" style="zoom: 67%;" />

**binlog （归档日志）**：是 ==Server 层生成的日志==，记录了所有数据库表结构变更和表数据修改的日志，主要**用于数据备份和主从复制**；



# Mysql锁

## ==30.按照加锁的范围，MySQL 有哪些锁？==

在 MySQL 里，根据加锁的范围，可以分为**全局锁、表级锁和行锁**三类。

**1、全局锁**

- 要使用全局锁，则要执行这条命令：

- 执行后，**整个数据库就处于只读状态了**，这时其他线程执行以下操作，都会被阻塞：

  - 对**数据**的增删改操作，比如 insert、delete、update等语句；
  - 对**表结构**的更改操作，比如 alter table、drop table 等语句。

- ```sql
  flush tables with read lock
  ```

- 如果要释放全局锁，则要执行这条命令。除此以外：当会话断开了，全局锁会被自动释放。

  ```sql
  unlock tables
  ```
  
  <img src="images/image-20230410140331764.png" alt="image-20230410140331764" style="zoom:80%;" />

**2、表级锁**

- 表示对==当前操作的整张表==加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。

- 表级锁定分为 表共享读锁（读锁）与表独占写锁（写锁）。

- **开销小**，加锁快;不会出现死锁;锁定粒度大，发出锁冲突的概率最高，**并发度最低**。

-  MySQL 里面表级别的锁有这几种：
  - ==表锁：==表锁除了会限制别的线程的读写外，**也会限制本线程接下来的读写操作。**
  - ==元数据锁（MDL）：==争对表结构的修改的锁，防止表数据的CRUD和表结构的修改冲突。
  - ==意向锁；==
  - ==AUTO-INC 锁；==

- ```sql
  //表级别的共享锁，也就是读锁；阻塞所有写的操作
  lock tables t_student read;
  
  //表级别的独占锁，也就是写锁；阻塞所有读、写操作。
  lock tables t_stuent write;
  
  //释放表锁。会释放当前会话的所有表锁：
  unlock tables;
  ```

  <img src="images/image-20230410141031754.png" alt="image-20230410141031754" style="zoom:80%;" />
  
- 我们不需要显示的使用 **元数据锁（MDL）**，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：

  - 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；阻塞表结构的写操作；
  - 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；阻塞表数据的CRUD；

  - 当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

  - 反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

- **意向锁**。

  - 在使用 InnoDB 引擎的表里对==某些记录==加上「共享锁」之前，需要==先在表级别==加上一个「意向共享锁」；
  - 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

  也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。普通的读 select 是不会加行级锁的，是利用 MVCC 实现一致性读，是无锁的；

  【注意】

  1、意向锁之间不会发生任何冲突；同一个表会加多个意向共享锁、意向独占锁；

  2、意向锁是表级锁，不会和行级锁发生任何冲突；

  3、意向锁会和表锁（共享、独占）发生冲突；

  意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突；

  ==表锁和行锁是满足读读共享、读写互斥、写写互斥的。==因为某个行记录加了独占锁后，他在修改数据撒，此时表锁想给这张表加共享锁的话就不行！！！大的范围要看小的范围情况，因为都是一家人。

  ==【意向锁的唯一作用】为了在加表锁时，快速判断内部某些行记录有没有被加锁；==如果有行记录被加了写锁，那么就此时不能加表锁，进队列等待；如果有被加了读锁，就不能加独占表锁，需要等待。





**3、行级锁**

- 行级锁是MySQL中锁定==粒度最细==的一种锁，表示只针对==当前操作的行==进行加锁。行级锁能大大减少
  数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。
- **开销大**，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，**并发度也最高**。





**MylSAM和InnoDB存储引擎使用的锁：**

- MylISAM采用 ==表级锁==(table-level locking)。
- lnnoDB支持 ==行级锁(row-level locking)和表级锁，默认为行级锁==



## 31-1.全局锁应用场景是什么？

全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。

**加全局锁又会带来什么缺点呢？**

加上全局锁，意味着整个数据库都是只读状态。那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。

**既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？**

有的，如果数据库的引擎支持的事务支持**可重复读的隔离级别**，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。

==备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 `–single-transaction` 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。==

InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。



## 31-2.MDL 不需要显示调用，那它是在什么时候释放的?

MDL 是在事务提交后才会释放，这意味着**事务执行期间，MDL 是一直持有的**。

那如果**数据库有一个长事务**（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：

1. 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；
2. 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
3. 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 **MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，**

那么==在线程 C修改表结构的操作 阻塞后，后续有对该表的 select 语句，就都会被阻塞==，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。

**为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？**

- 这是因为==申请 MDL 锁的操作会形成一个队列==，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

==所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。==







##  ==31.从锁的类别上分MySQL都有哪些锁呢?==

从锁的类别上来讲，有共享锁和排他锁。

- **共享锁（S）：**又叫做读锁。当用户要进行数据的读取时，对数据加上共享锁。==共享锁可以同时加上多个。==
- **排他锁（X）**：又叫做写锁。当用户要进行数据的写入时，对数据加上排他锁。==排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。==              

==指的都是同一个锁的级别下哦==，有全局锁、表级锁、行级锁；                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            

<img src="images/x锁和s锁.png" alt="img" style="zoom:80%;" />



## 32.InnoDB引擎的行锁是怎么实现的?

==InnoDB是基于索引来完成行锁==

例: select * from tab_with_index where id = 1 for update;

**for update**可以根据条件来完成行锁锁定，并且 id是有索引键的列，如果id不是索引键那么InnoDB将完成表锁，并发将无从谈起。

InnoDB 存储引擎的行锁是通过在索引上实现的，具体实现方式如下：

1. 当执行一个 SQL 语句时，InnoDB 存储引擎会根据查询条件在索引树上找到对应的索引节点，然后对该节点上的行加锁。

2. 如果查询条件是通过主键或唯一索引进行的，那么 InnoDB 存储引擎会直接锁定索引节点上的行。

3. 如果查询条件是通过非唯一索引进行的，那么 InnoDB 存储引擎会锁定索引节点上的行，并且锁定该节点之前和之后的间隙（Gap Lock）。

4. 如果查询条件是通过全表扫描进行的，那么 InnoDB 存储引擎会对整张表进行加锁。







## ==33.什么是死锁?怎么解决?==

死锁是指**一个或多个事务在同一资源上相互占用，并请求锁定对方的资源而造成的一种互相等待的现象**。

<img src="images/image-20230213203004763.png" alt="image-20230213203004763" style="zoom: 80%;" />

**常见的解决死锁的方法**

1、如果不同程序会**并发读取多个表，尽量约定以相同的顺序访问表**，可以大大降低死锁机会。

2、在**同一个事务中，尽可能做到一次锁定所需要的所有资源**，减少死锁产生概率;

3、对于非常容易产生死锁的业务部分，可以尝试使用**升级锁定颗粒度**，**通过表级锁定来减少死锁产生的概率;**





## ==35.为什么要分库分表?==

**分表**

- **单表数据量太大，会极大影响你的sql执行的性能**，到了后面你的sql可能就跑的很慢了。一般来说，就以我的经验来看，单表到**几百万**的时候就得分表了。
- **分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表**。比如按照用户id来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在200万以内。

**分库**

- **应用的并发量太大，会影响数据库的性能。**一个库一般我们经验而言，最多支撑到并发2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒1000左右，不要太大。
- **分库就是将一个库的数据拆分到多个库中，访问的时候就访问一个库好了**。

## ==36.分库分表方式？==

**垂直分库** 

​	就是把单一数据库==按照业务==进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。

<img src="images/image-20230213204134318.png" alt="image-20230213204134318" style="zoom: 67%;" />

**水平分库** 

​	是把 ==同一个表的数据拆分到不同的数据库，每个库表结构都一样== 中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。

<img src="images/image-20230213204148695.png" alt="image-20230213204148695" style="zoom:50%;" />

**垂直分表** 

​		是==对表的列的拆分，把一张列比较多的表拆分为多张表==。举个例子：我们可以将用户信息表中的一些列单独抽出来作为一个表。**（没有什么用）**

**水平分表** 

​		是==对表的行的拆分，把一张行比较多的表拆分为多张表==，**可以解决单一表数据量过大的问题。**

==水平分表只能解决单表数据量大的问题，为了提升性能，我们通常会选择将拆分后的多张表放在不同的数据库中。也就是说，水平分表通常和水平分库同时出现。==



## ==37.常见的分片算法有哪些？==

分片算法主要解决了数据被水平分片（水平分库分表）之后，数据究竟该存放在哪个库的表的问题。

**哈希分片** ：==按照某个字段hash一下均匀分布==，然后根据哈希值确定数据应被放置在哪个库表中。哈希分片比较==适合随机读写==的场景，==不太适合经常需要范围查询==的场景。

**范围分片** ：按照特性的范围区间（比如时间区间、ID区间）来分配数据，比如 将 `id` 为 `1~299999` 的记录分到第一个库， `300000~599999` 的分到第二个库。范围分片==适合经常范围查找==的场景，不太适合随机读写的场景（数据未被分散，容易出现热点数据的问题）。



## ==38.分库分表带来的问题==

记住，你在公司做的任何技术决策，不光是要考虑这个技术能不能满足我们的要求，是否适合当前业务场景，还要重点考虑其带来的成本。

引入分库分表之后，会给系统带来什么挑战呢？

- **无法join 操作** ： 同一个数据库中的表分布在了不同的数据库中，导致无法使用 join 操作。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。
- **无法有效实现事务** ：同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。
- **需要引入分布式 id** ：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。我们如何**为不同的数据节点生成全局唯一主键**呢？这个时候，我们就需要为我们的系统引入分布式 id 了。



## 38.什么是MySQL主从同步?

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器(master)，其余的服务器充当从服务器( slave) 。

> 因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。



## ==39.MySQL主从同步的目的?为什么要做主从同步?==

**1.通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能**，可以动态地调整从服务器的数量，从而调整整个数据库的性能。

**2.提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据**

**3.在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能**

**4.数据备份。**一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全



## 40.如何实现MySQL的读写分离?

其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后一台主数据库负责写，其他的从数据库负责读。**有了主从复制，才有读写分离**



## ==40.读写分离会带来什么问题？如何解决？==

读写分离对于提升数据库的并发非常有效，但是，同时也会引来一个问题：主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的 **主从同步延迟：导致写完读不到** 。

主从同步延迟问题的解决，没有特别好的一种方案。一般根据自己的业务场景，参考下面几种解决办法。

**1.强制将读请求路由到主库处理。**

既然你从库的数据过期了，那我就直接从主库读取嘛！这种方案虽然会增加主库的压力，但是，实现起来比较简单，也是我了解到的使用最多的一种方式。

比如 `Sharding-JDBC` 就是采用的这种方案。通过使用 Sharding-JDBC 的 `HintManager` 分片键值管理器，我们可以强制使用主库。

**2.延迟读取。**

既然主从同步存在延迟，那我就在延迟之后读取啊，比如主从同步延迟 0.5s,那我就 1s 之后再读取数据。这样多方便啊！方便是方便，但是也很扯淡。

不过，如果你是这样设计业务流程就会好很多：对于一些对数据比较敏感的场景，你可以在完成写请求之后，避免立即进行请求操作。比如你支付成功之后，跳转到一个支付成功的页面，当你点击返回之后才返回自己的账户。

**3.从库开启多线程进行复制**

从库开启多个线程，并行读取 relay log 中的日志，进行同步。



## ==41.MySQL主从复制流程和原理?==

基本原理流程，是3个线程以及之间的关联

**主：binlog线程**——记录下所有改变了数据库数据的语句，放进master上的binlog中;

**从：io线程**—―在使用start slave之后，负责**从master上拉取binlog内容，放进自己的relay log中**

**从：sql执行线程**——执行relay log中的语句；

<img src="images/主从复制过程.drawio.png" alt="MySQL 主从复制过程" style="zoom:80%;" />

## 42.如何定位及优化SQL语句的性能问题?

对于低性能的SQL语句的定位，最重要也是最有效的方法就是**使用执行计划**，MySQL提供了**explain**命令来查看语句的执行计划。**对于查询语句，最重要的优化方式就是使用索引。**



## ==43.大表数据查询，怎么优化？==

- **优化sql语句+索引；避免使用 select * ；**

- **加缓存机制, redis。大范围的统计信息可以写定时任务提前缓存；**

- **进行水平分表，例如将一年的数据拆分成12个月的表**

- 限定数据的范围：务必禁止不带任何限制数据范围条件的查询语句。比如:我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内;

- 主从复制，读写分离;  主库负责写，从库负责读

  

## ==44.MySQL数据库cpu飙升到500%的话他怎么处理?==

当cpu飙升到500%时，==1、先用操作系统命令top命令观察是不是MySQLd占用导致的，如果不是，找出占用高的进程，并进行相关处理。==

如果是MySQLd造成的，mysql>show processlist，看看里面跑的session情况，是不是有消耗资源的sql在运行。==2、找出消耗高的sql，看看执行计划是否准确,  index是否缺失，或者实在是数据量太大造成。==





## ==44.超大分页怎么处理?==

数据库层面,这也是我们主要集中关注的( 虽然收效没那么大 )，类似于  **select * from table where age> 20 limit 1000000 ,10**  这种查询其实也是有可以优化的余地的。这条语句需要load1000000数据然后基本上全部丢弃，只取10条当然比较慢。

- MySQL 根据 age 索引定位到第一个满足 age > 20 条件的记录，然后跳过前 1000000 条记录，接着读取接下来的 10 条记录，即是id。然后回主键索引查询。

当时我们可以修改为 `select * from table where id in (select id from table where age > 20 limit 1000000,10) `  。这样虽然也load了一百万的数据，但是由于**索引覆盖**，要查询的所有字段都在索引中，所以速度会很快。

解决超大分页,**其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可.**



## 45.coun(*)、count(1)、count(字段)哪个性能好？

<img src="images/af711033aa3423330d3a4bc6baeb9532.png" alt="图片" style="zoom:50%;" />

count() 是**统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个**。在通过 count 函数统计有多少个记录时，MySQL 的 server 层会维护一个名叫 count 的变量。server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL，那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。

==count(主键字段)==执行时会**优先选择二级索引**进行遍历，将读取到的记录返回给 server 层，**然后读取记录中的 id 值，判断是否为 NULL，**如果不为 NULL，就将 count 变量加 1。

- 因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小

==count(1)== 执行时也会**优先选择二级索引**进行遍历，将读取到的记录返回给 server 层，**但是不会读取记录中的任何字段的值，这也导致了比count(主键字段) 效率高一点**，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。

==count(`*`) 其实等于 count(`0`)，==也就是说，当你使用 count(`*`) 时，MySQL 会将 `*` 参数转化为参数 0 来处理。



## ==46.如何优化 count(*)？==

如果对一张大表经常用 count(*) 来做统计，其实是很不好的。

比如下面我这个案例，表 t_order 共有 1200+ 万条记录，我也创建了二级索引，但是执行一次 `select count(*) from t_order` 要花费差不多 5 秒！

==如果你的业务对于统计个数不需要很精确==，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值。

<img src="images/cd18879de0c0b37660f53a5f1af3d172.png" alt="图片" style="zoom:50%;" />

这时，我们就可以使用 show table status 或者 ==explain 命令来表进行估算。==

==执行 explain 命令效率是很高的，因为它并不会真正的去查询==，下图中的 rows 字段值就是 explain 命令对表 t_order 记录的估算值。

<img src="images/7590623443e8f225e5652109e6d9e3d2.png" alt="图片" style="zoom:50%;" />





## ==47.什么 SQL 语句会加行级锁？==

> InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁，所以后面的内容都是基于 InnoDB 引擎 的。所以，在说 MySQL 是怎么加行级锁的时候，其实是在说 InnoDB 引擎是怎么加行级锁的。

普通的 select 语句是不会对记录加锁的，因为它属于快照读，是通过 MVCC（多版本并发控制）实现的。

**当前读（锁定读）**才会去给行记录加锁；两种锁都可以加；

```sql
//对读取的记录加共享锁(S型锁)
select ... lock in share mode;
//对读取的记录加独占锁(X型锁)
select ... for update;
```

然后**删、改操作会直接加上 独占锁**。必须的嘛对吧；



## 48.行级锁有哪些种类？

不同隔离级别下，行级锁的种类是不同的。

**在读已提交隔离级别**下，行级锁的种类只有记录锁，也就是仅仅把一条记录锁上。

**在可重复读隔离级别**下，行级锁的种类除了有记录锁，还有间隙锁（目的是为了避免幻读），所以行级锁的种类主要有三类：

- **Record Lock，**记录锁，也就是仅仅把一条记录锁上；
- **Gap Lock，**间隙锁，锁定一个范围，但是不包含记录本身；
- **Next-Key Lock：**Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。

 ==**1、Record Lock**==

Record Lock 记录锁，锁住的是一条记录。也是有 S 锁和 X 锁。

==**2、Gap Lock**==

Gap Lock 锁定一个开区间范围，只存在于可重复读隔离级别，

**唯一目的是为了解决可重复读隔离级别下幻读的现象。**

假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。

![img](images/gap锁.drawio.png)

间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，**间隙锁之间是兼容的**，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。

==**3、Next-Key Lock**==

Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。

假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改和删除 id = 5 这条记录。

**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的**。

虽然**相同范围的间隙锁**是多个事务相互**兼容**的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的。



## 49.MySQL 是怎么加行级锁的？

==行级锁加锁规则比较复杂，不同的场景，加锁的形式是不同的。==

### 加索引的查询

**加锁的对象是索引**，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。

- 但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。那到底是什么场景呢？总结一句，
- ==在能使用**记录锁、间隙锁**就能**避免幻读**现象的场景下， next-key lock 就**会退化**成记录锁或间隙锁。==

#### 1.唯一索引等值查询

当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**。如查询id=2的，最后会锁住（1，5）间隙锁。

#### 2.唯一索引范围查询

范围查询和等值查询的加锁规则是不同的。

当唯一索引进行范围查询时，**会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁**：

- 情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会**退化成记录锁**。
- 情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中：
  - 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。
  - 当条件值的记录在表中，如果是「小于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。





#### 3.非唯一索引等值查询

当我们用非唯一索引进行等值查询的时候，因为存在两个索引，==一个是主键索引，一个是非唯一索引（二级索引）==，所以在加锁时，==同时会对这两个索引都加锁==，但是==对主键索引加锁==的时候，==只有满足查询条件的记录才会对它们的主键索引加锁。==



针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是**非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。



#### 4.非唯一索引范围查询

非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于**非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况**，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。



### 没有加索引的查询

前面的案例，我们的查询语句都有使用索引查询，也就是查询记录的时候，是通过索引扫描的方式查询的，然后对扫描出来的记录进行加锁。

**如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞**。

不只是锁定读查询语句不加索引才会导致这种情况，**update 和 delete 语句如果查询条件不加索引，**那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。

因此，**在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个记录索引加 next-key 锁，相当于把整个表锁住了**，这是挺严重的问题。





### 总结

我这里总结下， MySQL 行级锁的加锁规则。

==1、唯一索引等值查询：==

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**。

==2、非唯一索引等值查询：==

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后**在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。

==3、非唯一索引和唯一索引的范围查询的加锁规则不同之处在于：==

- 唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。
- 非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。

其实理解 MySQL 为什么要这样加锁，主要要以避免幻读角度去分析，这样就很容易理解这些加锁的规则了。

==4、不走索引查询==

还有一件很重要的事情，在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，**如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了**，这是挺严重的问题。





## 50.MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？

在 MySQL 的可重复读隔离级别下，针对当前读的语句会对**索引**加记录锁+间隙锁，这样可以避免其他事务执行增、删、改时导致幻读的问题。

有一点要注意的是，在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。



## 51.MySQL 的死锁发生



背景：就是新增订单的业务。因为订单是不能重复的，所以当时在新增订单的时候做了幂等性校验，做法就是**在新增订单记录之前，先通过 `select ... for update` 语句查询订单是否存在，如果不存在才插入订单记录。**

本次案例使用存储引擎 Innodb，隔离级别为可重复读（RR）。

接下来，我用实战的方式来带大家看看死锁是怎么发生的。

我建了一张订单表，其中 id 字段为主键索引，order_no 字段普通索引，也就是非唯一索引：

```sql
CREATE TABLE `t_order` (
  `id` int NOT NULL AUTO_INCREMENT,
  `order_no` int DEFAULT NULL,
  `create_date` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_order` (`order_no`) USING BTREE
) ENGINE=InnoDB ;
```

然后，先 `t_order` 表里现在已经有了 6 条记录：

![图片](images/54fc00f9f87a60ab7b5ba92d824a892d.png)

假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，**因为需要对订单做幂等性校验**，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下：

![img](images/90c1e01d0345de639e3426cea0390e80.png)

可以看到，两个事务都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。

**此时事务 A 在二级索引（INDEX_NAME : index_order）上加的是 X 型的 next-key 锁,，锁范围是`(1006, +∞]`**。

这里在查询记录是否存在的时候，使用了 `select ... for update` 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。

==注意！对于这种范围为 (1006, +∞] 的 next-key lock，两个事务是可以同时持有的，不会冲突。==因为 +∞ 并不是一个真实的记录，自然就不需要考虑 X 型与 S 型关系

### 总结

基本上两个事务发生了死锁，就是因为间隙锁的原因，也就是next-key锁退化成了间隙锁；

因为间隙锁可以可以相互兼容的。当事务A有了间隙锁时，事务B也有间隙锁，那么就会相互阻止对方在这段数据范围内的插入，造成死锁。

在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。







## 52.如何避免死锁？

死锁的四个必要条件：**互斥、请求保持、不可剥夺、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- **设置事务等待锁的超时时间**。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 `innodb_lock_wait_timeout` 是用来设置超时时间的，默认值时 50 秒
- **开启主动死锁检测**。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑，默认就开启。



## 53.有什么命令可以分析加了什么锁？

我们可以通过 `select * from performance_schema.data_locks\G;` 这条语句，查看事务执行 SQL 过程中加了什么锁。

```sql
select * from performance_schema.data_locks\G;
```

我们可以通过 `select * from performance_schema.data_locks\G;` 这条语句，查看事务执行 SQL 过程中加了什么锁。

我们以前面的事务 A 作为例子，分析下下它加了什么锁。

<img src="images/事务a加锁分析.png" alt="img" style="zoom: 50%;" />

从上图可以看到，共加了两个锁，分别是：

- 表锁：X 类型的意向锁；
- 行锁：X 类型的记录锁；

这里我们重点关注行级锁，图中 **LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思。**

通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁：

- 如果 LOCK_MODE 为 **`X`，说明是 next-key 锁；**
- 如果 LOCK_MODE 为 **`X, REC_NOT_GAP`，说明是记录锁；**
- 如果 LOCK_MODE 为 **`X, GAP`，说明是间隙锁；**



## 54.undo log 两大作用

- **实现事务回滚，保障事务的原子性**。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。
- **实现 MVCC（多版本并发控制）关键因素之一**。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。

## 55.为什么需要 redo log ？

redo log 是物理日志，记录了某个数据页做了什么修改，比如**对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新**，每当执行一个事务就会产生这样的一条或者多条物理日志。

在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。

当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。



## 56. 什么时候需要 / 不需要创建索引？

索引最大的好处是提高查询速度，但是索引也是有缺点的，比如：

- 需要占用物理空间，数量越大，占用空间越大；
- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；
- 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。

所以，索引不是万能钥匙，它也是根据场景来使用的。

#### [#](https://www.xiaolincoding.com/mysql/index/index_interview.html#什么时候适用索引)什么时候适用索引？

- 字段有唯一性限制的，比如商品编码；
- 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。

#### [#](https://www.xiaolincoding.com/mysql/index/index_interview.html#什么时候不需要创建索引)什么时候不需要创建索引？

- `WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
- 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- 表数据太少的时候，不需要创建索引；
- 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。
